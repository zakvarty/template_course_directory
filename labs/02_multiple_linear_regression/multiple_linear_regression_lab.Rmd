---
title: "Multiple Linear Regression Workshop"
author: "Chris Hallsworth and Zak Varty"
date: "13/08/2021"
output: 
  bookdown::html_document2:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bookdown)
```

***
# Set up

In this workshop we will be considering two data sets, each from the `faraway` package. The first data set is called `fat` and the second is called `globwarm`. 

*** 

__Task 1.1:__ Load both data sets into your working environment as `fat_df` and `gw_df` respectively. Use the R help, Google or `??` to write a few sentences describing each of these data sets.  


__Solution 1.1:__ 
<details><summary>Show answer</summary>

```{r task-11}
fat_df <- faraway::fat
gw_df <- faraway::globwarm

# Uncomment to open documentation for these
# ??faraway::fat
# ??faraway::globwarm
```

The `fat` data set details: "Age, weight, height, and 10 body circumference measurements are recorded for 252 men. Each man's percentage of body fat was accurately estimated by an underwater weighing technique". 

The `globwarm` data set details: "Average Northern Hemisphere Temperature from 1856-2000 and eight climate proxies from 1000-2000AD. Data can be used to predict temperatures prior to 1856." This is formatted as a data frame with 1001 observations of 10 variables. 
</details>

*** 

# Modelling body fat percentage

In the lecture videos we saw that body fat percentage is difficult to measure directly. We also saw that using a simple linear regression we can use chest circumference (which is much easier to to measure) as a way to predict body fat percentage. 

Here we try to improve this prediction by using multiple body measurements that are easily taken in a short medical interview. The doctor conducting these interview can reasonably be assumed to have access to a tape measure and weighing scales. 

*** 

__Task 1.2:__ Rename the column of `fat_df` that gives percentage body fat using Brozek's equation to "percentage". Retain `percentage` as the target variable of our analysis and remove all other columns of `fat_df` that could not be easily established during a short medical interview.

__Solution 1.2:__
<details><summary>Show answer</summary>

```{r solution-12}
variables_to_keep <- c("percentage", "age", "weight", "height", "neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")
fat_df$percentage <- fat_df$brozek
fat_df <- fat_df[,variables_to_keep]
```
</details>

***

__Task 1.3:__ Select 152 of the people in the study at random to form our training group and the remaining 100 will form our test group. (remember to do this in a reproducible way!) Split the data frame into `fat_df_train` and `fat_df_test`. 

__Solution 1.3:__
<details><summary>Show answer</summary>
```{r solution-13}
n <- nrow(fat_df)
n_train <- 152
n_test  <- n - n_train

set.seed(1234)
fat_df$is_training <- sample(
  x = rep(c(TRUE,FALSE), times = c(n_train, n_test)),
  size = n,
  replace = FALSE)

# Split data frame
fat_df_train <- fat_df[fat_df$is_training,]
fat_df_test <- fat_df[!fat_df$is_training,]

# Remove test/train indicator 
training_column_index <- which(names(fat_df_train) == "is_training")
fat_df_train <- fat_df_train[, -training_column_index]
fat_df_test <- fat_df_test[, -training_column_index]
```
</details>

***

## The null model

__Task 1.4:__ Fit a null model `lm_0` which has the same predicted body fat percentage for all individuals. What is this predicted value? Find the root mean squared prediction error (RMSPE) for this model. 

__Solution 1.4:__
<details><summary>Show answer</summary>

```{r solution-14, collapse=TRUE}
lm_0 <- lm(percentage ~ 1, data = fat_df_train)

rmspe <- function(prediction, observation){
  sqrt(mean((prediction - observation)^2))
}

lm_0_predictions <- predict(object = lm_0, newdata = fat_df_test)

lm_0_rmspe <- rmspe(lm_0_predictions, fat_df_test$percentage)

# Predicted values for first five people
unname(lm_0_predictions[1:5])

# Root mean squared prediction error of null model
lm_0_rmspe
```
</details>

***

## A simple linear regression

__Task 1.5:__ Fit all models with a single explanatory variable. Which gives the best RMSPE? Does it improve over the null model? 

__Solution 1.5:__
<details><summary>Show answer</summary>
```{r solution-15a, fig.align='center', fig.alt="Root mean squared prediction error for each simple linear regression. Several models have a RMSPE less than the null model. The model with the lowest RMSPE includes the abdominal measurement."}
n_explanatory <- ncol(fat_df_train) - 1
rmspes <- rep(NA, n_explanatory)

covariate_names <- names(fat_df_train)[-1]
formulae <- paste0("percentage ~ 1 + ", covariate_names)

for (i in seq_along(formulae)) {
  # fit linear model with covariate only i
  lm_i <- lm(formula = formulae[i], data = fat_df_train)
  
  # predict test set body fat percentages
  lm_i_predictions <- predict(object = lm_i, newdata =  fat_df_test)
  
  # calculate and record error metric
  rmspes[i] <- rmspe(lm_i_predictions, fat_df_test$percentage) 
}

# Create plot of RMSPE values
plot(
  x = c(0, seq_along(rmspes)),
  y = c(lm_0_rmspe, rmspes),
  xlab = "",
  ylab = "RMSPE",
  pch = 16,
  xaxt = "n")
abline(h = lm_0_rmspe)
axis(side = 1, at = c(0, seq_along(covariate_names)), labels = c("NULL", covariate_names), las = 3)
axis(side = 2)
mtext(side = 1, line = 4, text = "Additional explanatory variable")
```
```{r solution-15b, collapse=TRUE}
# The formula of the best fitting model
formulae[which.min(rmspes)]
```


By plotting the RMSPE for the null model and the simple linear regression using each explanatory variable we can see that: 

- Including most of the explanatory variables would lead to a reduction in prediction error as compared to the null model;
- The circumference of the abdomen has the greatest predictive power of any individual explanatory variable. 
</details>

***

__Task 1.6:__ Why do we use the RMSPE, which is based on the test data, rather than the RMSE (based on the training data) when selecting between potential models? 

__Solution 1.6:__
<details><summary>Show answer</summary>
Adding additional flexibility to a model (for example by including an additional explanatory variable) will always lead to a reduction in RMSE on the training data. If we only wanted to describe the few people measured in this data set as accurately as possible, we should include all explanatory variables. But that is not our goal. We want a model that generalises to the measurements of new individuals. By measuring the error on the test set we verify that the additional variability explained is not just noise in the training data. 
</details>

***

## Model selection

__Task 1.7:__ Explain what is meant by exhaustive-, forward- and backward- model selection. What are the benefits or drawbacks of each?

__Solution 1.7:__ 
<details><summary>Show answer</summary>
An exhaustive model selection tests all possible combinations of predictor variables and selects the model with the lowest test error. 

Forward model selection begins with a null model and successively adds the predictor variable which provides the greatest reduction in test error, until no further improvement can be found. 

Backward model selection begins with the saturated model, which includes all predictor variables and successively removes the variable which increases prediction error the most, until no further improvement can be found. 

Exhaustive selection is guaranteed to find the best combination of predictors but can require fitting an impractically high number of models (The number of possible models grows as $2^p$ where $p$ is the number of possible predictors). Forward and backward are heuristic search methods for this combinatorial optimisation problem: they usually find good models but are not guaranteed to find the best possible model. Generally, forward selection favours parsimonious models with few predictors while backward selection favours more complex models, which risk over-fitting to the training data. 

Finally, backward selection is not always possible. When there are a large number $p > n$ of predictors, there is not enough information in the data to fit the saturated model. In this case the regularisation methods we will meet later in this course, such as ridge and lasso regression, can be used instead.  
</details> 

***

__Task 1.8:__ Research and briefly describe the aims and implementation of forward-backward model selection.

<details><summary>Show answer</summary>
__Solution 1.8:__ Forward-backward model selection is another heuristic procedure to explore the space of all regression models in a principled way. Unlike forward or backward selection, forward-backward selection allows explanatory variables to be added and removed according to some decision rule. The decision rules are designed to achieve a balance between parsimony and model complexity. 
</details>

***

## A multiple linear regression

__Task 1.9:__ Which explanatory variables are included in the final multiple linear regression model when using forward model selection?

__Solution 1.9:__
<details><summary>Show answer</summary>
To make our lives easier when repeatedly plotting the test error we can write a function to do so. 

```{r plot-test-error}
plot_test_error <- function(base_formula, explanatory_variables, train_data, test_data, error_function){
  
  n_explanatory <- length(explanatory_variables)
  errors <- rep(NA, n_explanatory + 1)
  formulae <- c(
    base_formula,
    paste0(base_formula, " + ", explanatory_variables))
  
  for (i in seq_along(formulae)) {
  
    lm_i <- lm(formula = formulae[i], data = train_data)
  
    lm_i_predictions <- unname(predict(object = lm_i, newdata =  test_data))

    errors[i] <- error_function(
      prediction = lm_i_predictions, 
      observation = fat_df_test$percentage) 
  }
  
  plot(
    x = seq_along(errors),
    y = errors,
    xlab = "",
    ylab = "Test error",
    pch = 16,
    xaxt = "n")
  
  abline(h = errors[1])
  axis(
    side = 1,
    at = seq_along(errors),
    labels = c("NULL", explanatory_variables),
    las = 3)
  mtext(side = 1, line = 4, text = "Additional explanatory variable")
  
  paste0("Best perfoming model is: ", formulae[which.min(errors)])
}
``` 

We first test that this works for the simple linear regression case, which we hard coded earlier. 
```{r testing-plot-test-error}
plot_test_error(
  base_formula = "percentage ~ 1",
  explanatory_variables = covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test, 
  error_function = rmspe
)
```

We can now iteratively add explanatory variables until no further improvement in predictive performance is found.

<details><summary>Show forward selection code</summary> 
```{r solution-19, fig.align='center'}
remaining_covariate_names <- covariate_names
remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "abdom")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "weight")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "wrist")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "forearm")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "neck")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm + neck",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "biceps")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm + neck + biceps",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "age")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm + neck + biceps + age",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "thigh")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm + neck + biceps + age + thigh",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)

remaining_covariate_names <-
  remaining_covariate_names[-which(remaining_covariate_names == "hip")]

plot_test_error(
  base_formula = "percentage ~ 1 + abdom + weight + wrist + forearm + neck + biceps + age + thigh + hip",
  explanatory_variables = remaining_covariate_names,
  train_data = fat_df_train,
  test_data = fat_df_test,
  error_function = rmspe)
```
</details>

***

## Predicting body fat percentage
__Task 1.10:__ A doctor meets with a new patient with the following explanatory variables. Refit your selected regression model using `lm()` and use this to obtain a point estimate, a 90% confidence interval and a 90% prediction interval for the body fat percentage of this new patient. Describe, interpret and compare these three estimates for the doctor. 

```{r data-110}
new_patient <- data.frame(
  percentage = NA,
  age = 51, 
  weight = 211,
  height = 68.9,
  neck = 37.1,
  chest = 105,
  abdom = 87, 
  hip = 100.8, 
  thigh = 66.1, 
  knee = 40.2,
  ankle  = 24.8,
  biceps = 34.2,
  forearm = 29.1,
  wrist = 18.4
)

```

__Solution 1.10:__

<details><summary>Show answer</summary>
```{r solution-110, collapse=TRUE}
# Refitting the selected model using lm
selected_formula <- "percentage ~ 1 + abdom + weight + wrist + forearm + neck + biceps + age + thigh + hip"
fat_lm <- lm(
  formula = selected_formula, 
  data = fat_df_train)

# point estimate
predict(object = fat_lm, newdata = new_patient)

# confidence interval 
predict.lm(
  object = fat_lm,
  newdata = new_patient,
  interval = "conf",
  level = 0.9)

# prediction interval interval 
predict.lm(
  object = fat_lm,
  newdata = new_patient,
  interval = "pred",
  level = 0.9)
```
Under our fitted model, our best estimate of the new patient's body fat percentage is 12%. 

The confidence interval reflects our uncertainty about the mean body fat percentage of population with these body measurements. This uncertainty is caused by the regression coefficients being estimated based on only a sample of the population (and the assumption that a linear model is appropriate). The confidence interval 7.97-16.04\% covers the population mean body fat percentage for people with these body measurements with probability 0.9. 

The prediction interval additionally incorporates variability in body fat percentage _between_ people who have the same body measurements. This means that the prediction is therefore wider than the confidence interval. The prediction interval 3.91-20.10% covers the body fat percentage for this particular new patient with probability 0.9.
</details>

***

__Task 1.11:__ The doctor is curious to estimate her own body fat percentage and provides you with her details. Find a point estimate and a 95% prediction interval for her body fat percentage under your fitted model. Comment on your findings. 

```{r task-110}
doctor_measurements <- data.frame(
  percentage = NA,
  age = 40, 
  weight = 123,
  height = 63,
  neck = 35.0,
  chest = 91.2,
  abdom = 64.8, 
  hip = 100.8, 
  thigh = 67.1, 
  knee = 38.3,
  ankle  = 22.8,
  biceps = 27.8,
  forearm = 25.1,
  wrist = 15.9
)
```

<details><summary>Show answer</summary>

```{r solution-111, collapse=TRUE}
# prediction interval for doctor
predict(
  object = fat_lm,
  newdata = doctor_measurements,
  interval = "pred",
  level = 0.95)
```
Our point estimate for the doctor's body fat percentage is 2.73%. This is an extremely low value, to the point where if we believe this estimate then the doctor should be worried about her imminent organ failure. Our confidence interval even includes negative body fat percentage, and whatever that might mean for her health. So what is going on here? 

Firstly, neither our linear model nor the way we are constructing our confidence intervals ensures that our predictions will take values between 0 and 100 percent. These are mathematical problems, which can be addressed. Indeed, we will see how to fix these later in the course (e.g. using generalized linear models and deviance based confidence intervals).

Secondly, the doctor's body measurements mean that we are extrapolating in the space of explanatory variables: there are few training data that have explanatory variables similar to hers. Predictions in "unusual" or rarely observed areas of the explanatory variable space can be unreliable or even impossible, as we have seen with negative body fat percentages.

Finally, we are attempting to apply the regression model to a population that it was not trained to represent. The training and test data were both composed entirely of men's body measurements. Men and women have very different body fat distributions (both in a statistical and physical sense). It is not at all surprising that this model, optimised to describe the link between men's body measurement and fat percentage, performs poorly when applied to the data of a woman.
</details>

***

`Potenital topics to add: including interaction effect,evaluating goodness of fit and appropriateness, testing for outlier and points with high leverage.`

***
***
